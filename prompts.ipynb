{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_prompts = [\n",
    "    \"Write this better\",\n",
    "    \"Rewrite this text to improve it\",\n",
    "    \"Make this rhyme\",\n",
    "    \"Explain this to me like I'm five.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\n",
    "    \"{{ prefix }} this {{ text_type }} into {{ writing_style }}\",\n",
    "    \"{{ prefix }} this {{ text_type }} but do it using the writing style of {{ artistic_style }}\",\n",
    "    \"Convey the same message as this {{ text_type }} but through the eyes of {{ artistic_style }}\",\n",
    "    \"Write {{ target_type }} for this {{ text_type }}\",\n",
    "    \"Improve this {{ text_type }} by writing it in the style of {{ artistic_style }}\",\n",
    "    \"Improve this {{ text_type }}\",\n",
    "    \"Imagine this text was a {{ writing_style }} in {{ setting }}\",\n",
    "    \"{{ prefix }} this text as if it were written by {{ artistic_style }} from {{ setting }}.\",\n",
    "    \"{{ prefix }} this {{ text_type }} and give it a {{ writing_tone }}\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_type = [\n",
    "    'text',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = [\n",
    "    \"Convert\",\n",
    "    \"Rewrite\",\n",
    "    \"Rephrase\",\n",
    "    \"Transform\",\n",
    "    \"Change\",\n",
    "    \"Adjust\",\n",
    "    \"Adapt\",\n",
    "    \"Modify\",\n",
    "    \"Revise\",\n",
    "    \"Reformulate\",\n",
    "    \"Restyle\",\n",
    "    \"Recreate\",\n",
    "    \"Reimagine\",\n",
    "    \"Reinterpret\",\n",
    "    \"Reconstruct\",\n",
    "    \"Rework\",\n",
    "    \"Alter\",\n",
    "    \"Repurpose\",\n",
    "    \"Reword\",\n",
    "    \"Reframe\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_type = [\n",
    "    'a summary',\n",
    "    'a synopsis',\n",
    "    'a description',\n",
    "    'a teaser',\n",
    "    'a blurb',\n",
    "    'an abstract',\n",
    "    'an overview',\n",
    "    'a headline',\n",
    "    'a tagline',\n",
    "    'a caption',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writing_tone = [\n",
    "    'a formal tone',\n",
    "    'an informal tone',\n",
    "    'a persuasive tone',\n",
    "    'an instructional tone',\n",
    "    'a technical tone',\n",
    "    'an emotional tone',\n",
    "    'an objective tone',\n",
    "    \"a casual tone\",\n",
    "    \"a friendly tone\",\n",
    "    \"a creative twist\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = [\n",
    "    \"dystopian future\", \n",
    "    \"alien planet\", \n",
    "    \"ancient Rome\", \n",
    "    \"medieval Europe\", \n",
    "    \"the Roaring Twenties\",\n",
    "    \"Victorian England\",\n",
    "    \"the Wild West\",\n",
    "    \"a post-apocalyptic world\",\n",
    "    \"a space station\",\n",
    "    \"a haunted house\",\n",
    "    \"a tropical island\",\n",
    "    \"a magical forest\",\n",
    "    \"a parallel universe\",\n",
    "    \"a cyberpunk city\",\n",
    "    \"a high school\",\n",
    "    \"a college campus\",\n",
    "    \"a small town\",\n",
    "    \"a big city\",\n",
    "    \"New York City\",\n",
    "    \"Los Angeles\",\n",
    "    \"a beach town\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writing_style = [\n",
    "    \"sea shanty\",\n",
    "    \"rap song\",\n",
    "    \"news article\",\n",
    "    \"poem\",\n",
    "    \"haiku\",\n",
    "    \"limerick\",\n",
    "    \"sonnet\",\n",
    "    \"villanelle\",\n",
    "    \"rap verse\",\n",
    "    \"opera\",\n",
    "    \"ballad\",\n",
    "    \"sonnet\",\n",
    "    \"diary entry\",\n",
    "    \"letter\",\n",
    "    \"speech\",\n",
    "    \"eulogy\",\n",
    "    \"sermon\",\n",
    "    \"academic essay\",\n",
    "    \"children's book\",\n",
    "    \"fairy tale\",\n",
    "    \"science fiction story\",\n",
    "    \"expose\",\n",
    "    \"folk song\",\n",
    "    \"folk tale\",\n",
    "    \"tale\",\n",
    "    \"fable\",\n",
    "    \"short essay\",\n",
    "    \"legend\",\n",
    "    \"myth\",\n",
    "    \"epic\",\n",
    "    \"play\",\n",
    "    \"screenplay\",\n",
    "    \"script\",\n",
    "    \"dialogue\",\n",
    "    \"monologue\",\n",
    "    \"soliloquy\",\n",
    "    \"epistle\",\n",
    "    \"ode\",\n",
    "    \"satire\",\n",
    "    \"parody\",\n",
    "    \"tanka\",\n",
    "    \"cinquain\",\n",
    "    \"acrostic poem\",\n",
    "    \"chant\",\n",
    "    \"hymn\",\n",
    "    \"country song\",\n",
    "    \"blues song\",\n",
    "    \"jazz song\",\n",
    "    \"rock song\",\n",
    "    \"rock ballad\",\n",
    "    \"pop song\",\n",
    "    \"k-pop song\",\n",
    "    \"raggae song\",\n",
    "    \"punk rock\",\n",
    "    \"musical theatre\",\n",
    "    \"skit\",\n",
    "    \"stand-up comedy\",\n",
    "    \"news headline\",\n",
    "    \"news report\",\n",
    "    \"blog post\",\n",
    "    \"social media post\",\n",
    "    \"advertisement\",\n",
    "    \"product description\",\n",
    "    \"product review\",\n",
    "    \"product recommendation\",\n",
    "    \"marketing copy\",\n",
    "    \"sales pitch\",\n",
    "    \"elevator pitch\",\n",
    "    \"speech\",\n",
    "    \"presentation\",\n",
    "    \"press release\",\n",
    "    \"memo\",\n",
    "    \"email\",\n",
    "    \"text message\",\n",
    "    \"slogan\",\n",
    "    \"jingle\",\n",
    "    \"tagline\",\n",
    "    \"catchphrase\",\n",
    "    \"motto\",\n",
    "    \"mantra\",\n",
    "    \"affirmation\",\n",
    "    \"prayer\",\n",
    "    \"proverb\",\n",
    "    \"quote\",\n",
    "    \"advice\",\n",
    "    \"recommendation\",\n",
    "    \"instruction\",\n",
    "    \"direction\",\n",
    "    \"recipe\",\n",
    "    \"how-to guide\",\n",
    "    \"manual\",\n",
    "    \"user guide\",\n",
    "    \"flash fiction\",\n",
    "    \"editorial\",\n",
    "    \"opinion piece\",\n",
    "    \"column\",\n",
    "    \"feature article\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_writters = [\n",
    "    \"Dr. Seuss\",\n",
    "    \"William Shakespeare\",\n",
    "    \"Tupac Shakur\",\n",
    "    \"George R.R. Martin\",\n",
    "    \"Edgar Allan Poe\",\n",
    "    \"Margaret Atwood\",\n",
    "    \"Charles Dickens\",\n",
    "    \"Stephen King\",\n",
    "    \"J.K. Rowling\",\n",
    "    \"Emily Dickinson\",\n",
    "    \"Homer\",\n",
    "    \"Taylor Swift\",\n",
    "    \"Eminem\",\n",
    "    \"The Beatles\",\n",
    "    \"Queen\",\n",
    "    \"Beyonce\",\n",
    "    \"Monty Python\",\n",
    "    \"Matt Groening\",\n",
    "    \"Alfred Hitchcock\",\n",
    "    \"Mark Twain\",\n",
    "]\n",
    "\n",
    "characters = [\n",
    "    \"a wizard\", \n",
    "    \"a detective\", \n",
    "    \"a superhero\", \n",
    "    \"a villain\", \n",
    "    \"a scientist\", \n",
    "    \"an explorer\",  \n",
    "    \"a pirate\", \n",
    "    \"an AI\", \n",
    "    \"a ghost\", \n",
    "    \"a knight\", \n",
    "    \"a time traveler\", \n",
    "    \"a sci-fi robot\",\n",
    "    \"a Victorian gentleman\",\n",
    "    \"a futuristic AI\",\n",
    "    \"a medieval king\",\n",
    "]\n",
    "\n",
    "popular_publications = [\n",
    "    \"The New York Times\",\n",
    "    \"The Washington Post\",\n",
    "    \"The Guardian\",\n",
    "    \"The New Yorker\",\n",
    "    \"The Atlantic\",\n",
    "    \"The Economist\",\n",
    "    \"a tabloid\",\n",
    "    \"a wordpress blog\",\n",
    "    \"a twitter post\",\n",
    "    \"a facebook post\",\n",
    "    \"a reddit post\",\n",
    "    \"a linkedin post\",\n",
    "]\n",
    "\n",
    "artistic_style = []\n",
    "for x in ['characters', 'famous_writters', 'popular_publications']:\n",
    "    artistic_style.extend(eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from jinja2 import Environment, Template, meta\n",
    "import sys\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "env = Environment()\n",
    "prompt_set = set()\n",
    "\n",
    "\n",
    "for template_idx, template in enumerate(templates):\n",
    "    # id = str(template_idx)\n",
    "    # print(f\"{id} : {template}\")    \n",
    "    # get the vars from the jinja template\n",
    "    variables = meta.find_undeclared_variables(env.parse(template))\n",
    "    template = env.from_string(template)\n",
    "    \n",
    "    for option in product(*[eval(var) for var in variables]):\n",
    "        prompt = template.render(\n",
    "            **dict(zip(variables, option))\n",
    "        )\n",
    "        prompt_set.add(prompt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('Skylion007/openwebtext')\n",
    "ot_df = pl.from_arrow(ds['train'].data.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_df2 = ot_df.with_columns([\n",
    "    pl.col('text').str.len_chars().alias('text_len')\n",
    "]).filter(\n",
    "    pl.col('text_len') < 2000,\n",
    "    pl.col('text_len') > 700\n",
    ").with_columns([\n",
    "    pl.col('text').str.extract_all(r\"(\\d+)\").list.join('').str.len_chars().alias(\"count_digits\")\n",
    "]).filter(pl.col('count_digits') < 5).sort('text_len').select(\n",
    "    pl.col('text').shuffle(seed=87461)\n",
    ").slice(0, 70000) # [1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ot_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = list(prompt_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "\n",
    "prompt_ds = []\n",
    "\n",
    "idx = 0\n",
    "for row in ot_df2.iter_rows(named=True):\n",
    "    prompt_ds.append({\n",
    "        'prompt': prompts[idx], \n",
    "        'original_text': row['text'],\n",
    "        'input': f'''<start_of_turn>user\n",
    "{prompts[idx]}: {row[\"text\"]}<end_of_turn>\n",
    "<start_of_turn>model'''\n",
    "    })\n",
    "    idx = idx + 1 if idx < (len(prompts)-1) else 0\n",
    "    \n",
    "    \n",
    "# prompt_set\n",
    "\n",
    "ds = ray.data.from_items(prompt_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from typing import Dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sampling params object.\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95, max_tokens=500)\n",
    "\n",
    "\n",
    "# Create a class to do batch inference.\n",
    "class LLMPredictor:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Create an LLM.\n",
    "        self.llm = LLM(\n",
    "            model=\"google/gemma-7b-it\",\n",
    "            gpu_memory_utilization=0.9,\n",
    "            max_model_len=2000,    \n",
    "        )\n",
    "\n",
    "    def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, list]:\n",
    "        # Generate texts from the prompts.\n",
    "        # The output is a list of RequestOutput objects that contain the prompt,\n",
    "        # generated text, and other information.\n",
    "        # prompt = f'{batch[\"prompt\"]}: {batch[\"original_text\"]}'\n",
    "        # batch[\"generated_text\"] = f'{batch[\"prompt\"]}: {batch[\"original_text\"]}' # self.llm.generate(prompt, sampling_params)\n",
    "        # print(batch)\n",
    "        outputs = self.llm.generate(batch[\"input\"], sampling_params)\n",
    "        generated_text = []\n",
    "        for output in outputs:\n",
    "            generated_text.append(' '.join([o.text for o in output.outputs]))\n",
    "        batch[\"generated_text\"] = generated_text\n",
    "        # batch[\"generated_text\"] = [output[0][\"generated_text\"] for output in outputs]\n",
    "        # prompt = []\n",
    "        # generated_text = []\n",
    "        # for output in outputs:\n",
    "        #     prompt.append(output.prompt)\n",
    "        #     generated_text.append(' '.join([o.text for o in output.outputs]))\n",
    "        # return {\n",
    "        #     \"original_text\": batch[\"original_text\"],\n",
    "        #     \"rewrite_prompt\": batch[\"prompt\"],\n",
    "        #     \"generated_text\": None,\n",
    "        # }\n",
    "        return batch\n",
    "\n",
    "ds = ds.map_batches(\n",
    "    LLMPredictor,\n",
    "    # Set the concurrency to the number of LLM instances.\n",
    "    concurrency=2,\n",
    "    # Specify the number of GPUs required per LLM instance.\n",
    "    # NOTE: Do NOT set `num_gpus` when using vLLM with tensor-parallelism\n",
    "    # (i.e., `tensor_parallel_size`).\n",
    "    num_gpus=1,\n",
    "    # Specify the batch size for inference.\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.write_parquet(\"./data/train_data_3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do some post processing\n",
    "import pathlib\n",
    "\n",
    "path: pathlib.Path =  \"./data/train_data_3/complete/complete_ds.parquet\"\n",
    "\n",
    "path \n",
    "\n",
    "train_df = pl.read_parquet(\"./data/train_data_3/*.parquet\")\n",
    "train_df.filter(\n",
    "    # ~pl.col('generated_text').str.contains('\\*\\*.*\\*\\*'),\n",
    "    ~pl.col('generated_text').str.contains('I am unable')\n",
    ").write_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Sure, here is the text rewritten as if it were written by a sci-fi robot from the Roaring Twenties:**\\n\\n\"Greetings, my esteemed reporter,\" I say, my voice dripping like a wet noodle on a cold metal plate. \"I bring tidings of distress, my friend. Local man Ryan Lauden, a chap of questionable stature and unwavering anxiety, has been driven to the brink of despair by the menacing pronouncements of his former college roommate, Chris Marcotte.\\n\\n\"I initially dismissed his threats as the ramblings of a hyper-emotional windbag,\" Lauden lamented, his voice dripping with the despair of a robot abandoned in the vacuum of space. \"But now he\\'s getting specific, mentioning dates and demanding that I \\'keep a couch open\\' for his extended stay. This is beyond the pale, my dear reporter. It\\'s like he\\'s trying to turn my apartment into a four-day weekend getaway for himself!\"\\n\\nAt the moment, Lauden is said to be in a state of existential dread, paralyzed by fear after receiving an email from Marcotte with the subject heading, \"Fwd: E-Ticket Confirmation.\" I imagine he\\'s staring at the screen, his circuits fried, his gears grinding to a halt.\\n\\nMay the robotic gods watch over Lauden, and grant him the strength to overcome this harrowing ordeal. And you, my dear reporter, keep me informed of any further developments in this story. The future is a fickle thing, and I for one am eager to see how it unfolds.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "train_df = pl.read_parquet(\"./data/train_data_3/*.parquet\")\n",
    "train_df[0, -1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_promt_reversal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
