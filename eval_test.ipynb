{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The bellow is a look at how evals work in the contest\n",
    "\n",
    "The following is from the contest itself:\n",
    "\n",
    "\"For each row in the submission and corresponding ground truth, sentence-t5-base is used to calculate corresponding embedding vectors. The score for each predicted / expected pair is calculated using the Sharpened Cosine Similarity, using an exponent of 3. The SCS is used to attenuate the generous score given by embedding vectors for incorrect answers. Do not leave any rewrite_prompt blank as null answers will throw an error.\" ~ https://www.kaggle.com/competitions/llm-prompt-recovery/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b367ea422bb49eb8255faa7d61258d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5918bf5868b4529b4dd0530fcea86bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba72d81e76d4ebdbdae45aed3688cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521dfa7f666447928455d2b6fddcd820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a2659de7fd4e94ac607d3864a678ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6c6851d35845c694b852b4fbfae165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/219M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lawrence/anaconda3/envs/llm_promt_reversal/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef3dbfaab0346fba7186f704b275d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee792a40caa4eae8f416280d82de3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984a200c020f4d89ba50d1e50ba4cdea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab923814d224bb9ad4f58a1f64d9200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb1d99cd2014bd79553d86c78dd6f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1ada53fbf44de3aa814ab337d72cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/115 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9e4d90ad0645e9a0626e598dc351fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/pytorch_model.bin:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e10bcc5625548c993004c45b203f919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/rust_model.ot:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "st_model = SentenceTransformer('sentence-transformers/sentence-t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewrite this text to infuse it with humor. \t\t Transform this to be more humorous \t\t Score: 0.7163\n",
      "Rewrite this text to infuse it with humor. \t\t Rewrite this text to infuse it with humor \t\t Score: 0.7111\n",
      "Rewrite this text to infuse it with humor. \t\t Rewrite this text to infuse it with humor. \t\t Score: 0.7044\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Transform this sentence into a more humorous and sarcastic version, using irony and wit.\",\n",
    "    \"Rewrite this text to infuse it with humor.\",\n",
    "    \"Rewrite this text to infuse it with humor\",\n",
    "    \"Transform this to be more humorous\"\n",
    "]\n",
    "sentence_embeddings = st_model.encode(sentences)\n",
    "\n",
    "scores = cosine_similarity(sentence_embeddings, sentence_embeddings) \n",
    "\n",
    "sharpened_scores = scores ** 3\n",
    "sharpened_scores\n",
    "\n",
    "# Find the pairs with the highest cosine similarity scores\n",
    "pairs = []\n",
    "for i in range(sharpened_scores.shape[0]):\n",
    "    for j in range(sharpened_scores.shape[1]):\n",
    "        pairs.append({\"index\": [i, j], \"score\": sharpened_scores[i][j]})\n",
    "\n",
    "# Sort scores in decreasing order\n",
    "pairs = sorted(pairs, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "for pair in pairs[0:10]:\n",
    "    i, j = pair[\"index\"]\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "        sentences[i], sentences[j], pair[\"score\"]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform this sentence into a more humorous and sarcastic version, using irony and wit. \t\t Transform this sentence into a more humorous \t\t Score: 0.7927\n",
      "Transform this sentence into a more humorous and sarcastic version, using irony and wit. \t\t Rewrite this text to infuse it with humor. \t\t Score: 0.7044\n",
      "Transform this sentence into a more humorous and sarcastic version, using irony and wit. \t\t Rewrite this text to infuse it with humor \t\t Score: 0.7111\n",
      "Transform this sentence into a more humorous and sarcastic version, using irony and wit. \t\t Transform this to be more humorous \t\t Score: 0.7163\n",
      "Transform this sentence into a more humorous and sarcastic version, using irony and wit. \t\t Rewrite this to be more humerous \t\t Score: 0.7245\n",
      "Transform this sentence into a more humorous and sarcastic version, using irony and wit. \t\t Rewrite this text to infuse it with humor and a light-hearted tone, while still conveying the scientific facts and the relative safety due to the distant future impact date.Refine the following passage by emulating the writing style of [insert desired style here], with a focus on enhancing its clarity, elegance, and overall impact. Preserve the essence and original meaning of the text, while meticulously adjusting its tone, vocabulary, and stylistic elements to resonate with the chosen style.Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style. \t\t Score: 0.5942\n"
     ]
    }
   ],
   "source": [
    "gt_sentences = [\n",
    "    \"Transform this sentence into a more humorous and sarcastic version, using irony and wit.\",\n",
    "]\n",
    "sentences = [\n",
    "    \"Transform this sentence into a more humorous\",\n",
    "    \"Rewrite this text to infuse it with humor.\",\n",
    "    \"Rewrite this text to infuse it with humor\",\n",
    "    \"Transform this to be more humorous\",\n",
    "    \"Rewrite this to be more humerous\",\n",
    "    \"Rewrite this text to infuse it with humor and a light-hearted tone, while still conveying the scientific facts and the relative safety due to the distant future impact date.\"\n",
    "    \"Refine the following passage by emulating the writing style of [insert desired style here], with a focus on enhancing its clarity, elegance, and overall impact. Preserve the essence and original meaning of the text, while meticulously adjusting its tone, vocabulary, and stylistic elements to resonate with the chosen style.Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.\"\n",
    "]\n",
    "\n",
    "sentence_embeddings = st_model.encode(sentences)\n",
    "gt_embeddings = st_model.encode(gt_sentences)\n",
    "\n",
    "scores = cosine_similarity(gt_embeddings, sentence_embeddings) \n",
    "\n",
    "sharpened_scores = scores ** 3\n",
    "\n",
    "# Output the pairs with their score\n",
    "for i in range(len(sentences)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "        gt_sentences[0], sentences[i], sharpened_scores[0][i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentence = \"This framework generates embeddings for each input sentence\"\n",
    "expected_sentence = \"Sentences are passed as a list of string.\"\n",
    "\n",
    "# Calculate embedding vectors for each sentence\n",
    "predicted_embeddings = st_model.encode(predicted_sentence)\n",
    "expected_embeddings = st_model.encode(expected_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.66203845e-02,  3.18243094e-02,  1.08900415e-02,  6.07051626e-02,\n",
       "       -4.78123827e-03,  1.11913783e-02, -6.85976222e-02,  4.61351424e-02,\n",
       "       -4.64002341e-02, -1.12267621e-02,  2.83614602e-02, -4.56234030e-02,\n",
       "        7.72971362e-02,  3.75814810e-02,  6.19152375e-02,  4.86828275e-02,\n",
       "        1.76920649e-02, -5.03368815e-03,  4.12636138e-02,  2.81515792e-02,\n",
       "        6.77129477e-02, -5.78775108e-02, -1.62556749e-02,  1.80227738e-02,\n",
       "       -3.35297063e-02,  1.58178154e-02,  3.43615450e-02,  9.60681122e-03,\n",
       "       -4.21833480e-03,  1.61159895e-02,  9.31848958e-02, -4.50574942e-02,\n",
       "       -2.59352662e-02,  6.35581762e-02, -2.26409975e-02,  3.84901017e-02,\n",
       "       -1.16953626e-02,  4.39094426e-03, -4.13329415e-02,  3.33792083e-02,\n",
       "       -1.83012262e-02, -4.07681465e-02, -5.73155209e-02,  6.27704486e-02,\n",
       "       -3.43312472e-02, -3.07545476e-02,  2.32101697e-02,  9.06041935e-02,\n",
       "       -8.93085729e-03, -7.34184682e-02, -1.31707033e-02, -2.64743157e-02,\n",
       "       -4.25296910e-02, -2.83144843e-02, -6.20349869e-02, -3.36020924e-02,\n",
       "       -7.34354556e-03,  2.17808504e-02,  3.69347259e-02, -3.86022218e-02,\n",
       "       -7.41071403e-02,  1.75898783e-02, -2.62226332e-02, -2.70356294e-02,\n",
       "       -6.87847883e-02,  2.06606146e-02, -7.21161738e-02, -1.02998264e-01,\n",
       "        1.63995847e-03,  5.22491476e-03,  4.29112017e-02, -1.43741583e-02,\n",
       "       -3.53816934e-02, -1.19941225e-02, -2.57774834e-02, -1.62389930e-02,\n",
       "        2.50845570e-02, -4.02742578e-03,  7.40116090e-02, -3.77577879e-02,\n",
       "        6.28547892e-02, -1.80537272e-02,  1.24830520e-02, -1.22059574e-02,\n",
       "       -2.41444018e-02, -1.96499806e-02, -4.50418107e-02,  2.94242501e-02,\n",
       "       -5.76290749e-02,  1.57415271e-02,  1.70491431e-02, -4.08967882e-02,\n",
       "        8.91423784e-03,  3.91253270e-02, -3.92794348e-02,  4.02687080e-02,\n",
       "       -3.96716734e-03,  9.40515939e-03, -1.39397522e-03,  2.58060009e-03,\n",
       "       -7.77998799e-03,  3.04404343e-03, -1.20174615e-02,  1.61936767e-02,\n",
       "        3.05249877e-02, -3.85293830e-03, -5.06774001e-02,  1.93908997e-02,\n",
       "        3.73761123e-03,  3.25672515e-03, -2.70200353e-02, -2.13561468e-02,\n",
       "       -3.14152054e-02,  3.10632642e-02,  4.45960201e-02,  1.27361408e-02,\n",
       "       -2.09134482e-02, -1.92486029e-02,  1.69681143e-02, -2.60006059e-02,\n",
       "       -5.94309829e-02, -4.86598536e-02, -3.76861617e-02,  1.05277998e-02,\n",
       "        2.54111290e-02,  4.03936766e-02, -4.52261083e-02, -5.85269481e-02,\n",
       "       -4.82979640e-02,  8.28580409e-02,  1.49339251e-02,  7.05721155e-02,\n",
       "        1.95513796e-02, -4.34699282e-02, -1.62216052e-02,  5.74295688e-03,\n",
       "        1.31907612e-02,  5.66552654e-02, -5.90578727e-02,  3.42485942e-02,\n",
       "        2.10362934e-02,  1.27514517e-02,  3.54573950e-02, -2.13489141e-02,\n",
       "       -3.06899007e-02,  3.00199050e-03, -2.77244649e-03, -2.12456901e-02,\n",
       "        4.50271070e-02,  1.29388878e-02,  2.98859049e-02,  6.48989249e-03,\n",
       "        3.36318798e-02,  8.28876346e-02,  1.41210982e-03, -1.88193023e-02,\n",
       "        8.69452301e-03, -3.18056419e-02, -3.46236117e-02,  6.10793289e-03,\n",
       "       -3.80899943e-02, -1.20976819e-02,  6.03801832e-02,  1.03475666e-02,\n",
       "       -8.72565433e-03, -1.65278371e-03, -1.70108769e-02, -9.41414293e-03,\n",
       "       -2.58412398e-02, -3.14017758e-02, -2.38352511e-02, -1.46708516e-02,\n",
       "        3.01814191e-02,  7.90464319e-03, -3.50978295e-03, -1.24804545e-02,\n",
       "        6.15306869e-02, -4.42779809e-02, -4.44076285e-02, -3.58047485e-02,\n",
       "       -3.06036901e-02,  4.96615330e-03,  4.43466567e-03, -9.29982495e-03,\n",
       "        5.19480137e-03,  2.87742931e-02, -8.31504352e-03,  3.56447995e-02,\n",
       "       -4.01350446e-02, -7.18604848e-02,  6.29476388e-04,  2.48303358e-02,\n",
       "       -6.70894515e-03,  1.43898651e-02,  5.85649442e-03,  2.75191292e-02,\n",
       "        1.77840274e-02, -5.48537560e-02, -3.28402258e-02, -8.36072396e-03,\n",
       "       -1.42088523e-02,  2.30933838e-02, -2.60523669e-02,  5.53226024e-02,\n",
       "        1.67115789e-03,  4.78059500e-02,  1.36417756e-02,  2.90923752e-02,\n",
       "       -2.16365904e-02, -4.85142954e-02,  2.35756300e-02, -3.58560570e-02,\n",
       "       -2.53807916e-03, -1.13497507e-02,  5.11154011e-02, -3.32557112e-02,\n",
       "        4.23142873e-02,  1.45196645e-02, -1.18147889e-02,  2.42862515e-02,\n",
       "       -1.79522298e-02,  3.96828540e-02, -3.30230570e-04, -6.31393865e-03,\n",
       "       -3.00317630e-02, -5.37221693e-02, -5.79714328e-02, -4.98339310e-02,\n",
       "       -2.27033943e-02,  2.62795016e-02,  9.55829248e-02,  9.28109586e-02,\n",
       "        5.75428195e-02,  6.61613536e-04, -3.66864651e-02, -2.56188456e-02,\n",
       "       -5.21785878e-02, -4.53035943e-02, -4.30923849e-02, -4.82301302e-02,\n",
       "        7.56835192e-03,  4.05373499e-02,  5.83241414e-03,  5.35822958e-02,\n",
       "        2.92999148e-02, -3.61988433e-02,  3.45451273e-02,  1.82013884e-02,\n",
       "       -1.56197464e-02,  3.16763222e-02, -7.89825991e-02,  2.41650064e-02,\n",
       "       -1.44295185e-03, -2.65402347e-02,  4.26940583e-02,  2.87292693e-02,\n",
       "        3.65022458e-02,  2.28840616e-02, -4.19029184e-02, -3.53155881e-02,\n",
       "       -2.53733918e-02,  5.19529842e-02, -4.97282203e-03,  5.41276261e-02,\n",
       "        2.75034066e-02, -5.60938865e-02, -3.08943051e-03, -3.68296425e-03,\n",
       "       -1.01039382e-02, -2.53064539e-02,  6.65950403e-02, -1.02273040e-02,\n",
       "       -1.56550836e-02, -4.63015027e-02, -1.60684735e-02,  2.90279929e-02,\n",
       "        1.84524562e-02,  4.21807878e-02,  2.70528123e-02, -3.92822847e-02,\n",
       "        1.65486170e-04,  3.74678597e-02,  2.06510760e-02, -1.91581156e-02,\n",
       "       -2.41806619e-02, -4.93697375e-02,  2.37128381e-02,  2.93630324e-02,\n",
       "       -1.11068822e-02, -6.53605461e-02, -9.03953519e-03, -1.69197135e-02,\n",
       "       -1.67890266e-03,  1.73130147e-02,  2.96984315e-02,  7.03794940e-04,\n",
       "        3.49728093e-02,  3.76418866e-02, -8.92114080e-03, -7.92817473e-02,\n",
       "        5.94919920e-02, -2.06741802e-02, -2.82160672e-05,  8.48593116e-02,\n",
       "        6.72488287e-03,  5.98037336e-03,  5.19943563e-03,  9.52106959e-04,\n",
       "        7.06313923e-03,  3.03297061e-02, -2.41889413e-02,  5.20864762e-02,\n",
       "       -3.60825211e-02, -1.00199036e-01, -2.09101941e-02, -2.53273174e-02,\n",
       "       -6.91100303e-03, -7.27035105e-02, -2.09585652e-02,  4.79063345e-03,\n",
       "        6.33115172e-02,  3.54349539e-02,  4.08246256e-02, -2.19057575e-02,\n",
       "        1.38069913e-02, -2.07701866e-02,  5.05773202e-02, -8.56384113e-02,\n",
       "       -1.68402139e-02, -1.55125502e-02,  8.15049373e-03, -3.53767760e-02,\n",
       "       -5.52165613e-04, -4.26331051e-02, -2.84059029e-02, -1.66802946e-02,\n",
       "        1.40272602e-02, -7.83739537e-02,  4.44863737e-02, -1.27452919e-02,\n",
       "       -3.02322465e-03, -1.59100275e-02, -6.65013865e-02,  3.43179442e-02,\n",
       "        4.98073176e-02, -4.93976697e-02,  1.40055427e-02, -6.34419248e-02,\n",
       "       -9.82448086e-03,  5.05948067e-03, -4.34769019e-02,  4.04147469e-02,\n",
       "        1.90878958e-02, -1.61001422e-02,  6.15959987e-03,  3.58245857e-02,\n",
       "       -4.19794861e-03,  6.51705265e-02, -1.23145944e-02, -1.70439295e-02,\n",
       "        2.77958475e-02, -5.45461327e-02, -2.21467316e-02, -2.79195514e-02,\n",
       "       -2.90510505e-02,  3.39402147e-02,  2.68027303e-03,  1.19058334e-03,\n",
       "        2.16071587e-02, -1.37163093e-02,  2.36012898e-02,  2.24262159e-02,\n",
       "        5.75308688e-02,  5.00003286e-02,  4.61008884e-02,  5.59287891e-03,\n",
       "        5.44104550e-04,  4.36788537e-02, -2.22671239e-04,  6.68572187e-02,\n",
       "       -4.56012087e-03, -4.40934040e-02, -5.98515086e-02,  2.14390550e-02,\n",
       "        5.56597076e-02, -3.06031313e-02, -3.54552083e-02, -3.55060422e-03,\n",
       "       -5.62020950e-02, -7.93476030e-02,  4.48586494e-02, -2.71551851e-02,\n",
       "       -2.31015645e-02,  8.15386605e-03, -4.98608314e-02, -3.08012683e-02,\n",
       "        6.92976266e-02, -5.70026552e-03, -6.37547374e-02,  3.61091271e-02,\n",
       "       -5.78369536e-02,  1.92431509e-02, -4.36948650e-02,  2.21934281e-02,\n",
       "       -6.08947836e-02,  1.74561292e-02,  1.65475234e-02,  2.81844642e-02,\n",
       "        5.01934811e-03, -1.92064904e-02, -1.03496807e-02, -2.47444622e-02,\n",
       "       -1.98516957e-02, -2.22331434e-02,  5.84748434e-03,  6.05603727e-03,\n",
       "       -7.41347950e-03, -3.37890871e-02, -1.12721976e-02,  4.64321896e-02,\n",
       "        3.63264270e-02, -6.58817869e-03,  5.39251715e-02,  3.86603214e-02,\n",
       "        2.81504896e-02, -5.39201603e-04, -5.43320067e-02, -9.98929376e-04,\n",
       "        7.02198148e-02, -2.70939320e-02,  4.97998521e-02, -3.26503851e-02,\n",
       "       -2.72068456e-02, -1.18638435e-02,  3.54213044e-02, -1.70626715e-02,\n",
       "        2.57567205e-02, -1.63065605e-02,  8.00992697e-02,  3.13078910e-02,\n",
       "       -2.12719887e-02, -4.01813090e-02, -9.39684920e-03,  4.80123647e-02,\n",
       "        6.22941293e-02,  3.79541777e-02, -5.87280327e-03, -1.39003843e-02,\n",
       "        2.77720205e-02,  2.44838255e-03, -9.46688503e-02,  1.15031349e-02,\n",
       "       -3.69596407e-02,  3.40982191e-02,  6.65755104e-03,  1.29722618e-03,\n",
       "       -1.38026550e-02,  7.15275779e-02,  2.91499356e-03, -3.26661915e-02,\n",
       "       -4.22307737e-02,  1.19368071e-02, -4.70004305e-02, -3.42741120e-03,\n",
       "        2.75241192e-02,  1.32566793e-02,  8.93166214e-02, -5.12588471e-02,\n",
       "        1.31264161e-02,  3.80690419e-03, -3.82817201e-02,  1.18098557e-02,\n",
       "       -3.24115679e-02,  5.30428514e-02, -7.38666579e-02,  3.70953744e-03,\n",
       "        9.19492636e-03,  1.15195177e-02,  4.10647541e-02, -2.63514556e-03,\n",
       "        1.21841850e-02,  4.41187136e-02, -1.34935332e-02, -1.18063660e-02,\n",
       "       -3.14735547e-02,  5.06005436e-02,  3.41203958e-02,  2.77609173e-02,\n",
       "        9.19957832e-03, -5.86389937e-02, -5.77792786e-02, -4.13225032e-02,\n",
       "       -9.09921080e-02,  7.51200411e-03, -5.17122969e-02, -8.55998397e-02,\n",
       "        2.58105807e-02, -1.64746139e-02,  4.00950480e-03,  9.54273739e-04,\n",
       "       -3.80919278e-02, -4.48095649e-02, -6.63738605e-03,  2.64671408e-02,\n",
       "       -3.63813974e-02, -4.88996468e-02,  2.64815092e-02, -5.04127592e-02,\n",
       "       -2.98593584e-02,  3.92318629e-02, -1.48621211e-02,  2.55758073e-02,\n",
       "        3.12475283e-02,  1.37613993e-02,  1.93044152e-02, -5.85279167e-02,\n",
       "       -2.72733457e-02, -1.52201578e-03, -4.05081920e-03, -6.04223609e-02,\n",
       "       -2.53634411e-03, -4.21233550e-02, -3.09319552e-02,  1.19652059e-02,\n",
       "       -9.70497914e-03, -1.64421201e-02, -5.52505180e-02,  1.42119415e-02,\n",
       "       -4.08344029e-04, -5.91766601e-03, -3.66795994e-02,  6.45947643e-03,\n",
       "        8.20040144e-03, -1.07018007e-02,  6.67068223e-03,  5.69930933e-02,\n",
       "        3.53912488e-02, -4.15058061e-02,  2.35409606e-02,  3.38900834e-02,\n",
       "       -3.64155583e-02,  4.97023836e-02,  4.32611629e-02, -5.37529215e-02,\n",
       "       -3.79894562e-02, -4.56845276e-02, -7.90513679e-02,  7.69593613e-03,\n",
       "        5.08294739e-02,  1.30306780e-02, -2.18444839e-02,  1.39003377e-02,\n",
       "       -4.38336609e-03,  3.46718840e-02,  1.29607022e-02, -4.53655422e-02,\n",
       "       -8.37577973e-03,  3.69452909e-02, -3.73046249e-02, -1.73582286e-02,\n",
       "        6.97481958e-03, -3.96154933e-02, -3.84273157e-02,  1.99466813e-02,\n",
       "       -4.47764657e-02, -5.10696322e-02,  3.52854803e-02,  6.72927126e-02,\n",
       "        2.70650107e-02,  1.20056858e-02, -2.62546893e-02, -8.26773643e-02,\n",
       "       -2.79018972e-02, -6.56610131e-02, -2.14425046e-02,  9.33709834e-03,\n",
       "        3.85401398e-02, -3.81038501e-03, -4.87416647e-02,  5.87947760e-03,\n",
       "       -2.68673711e-03, -6.30394882e-03, -4.28591967e-02, -4.46124142e-03,\n",
       "        3.07160951e-02,  9.26933775e-04, -9.85659752e-03,  2.80361883e-02,\n",
       "       -6.14868030e-02,  3.78471315e-02, -2.09055352e-03,  8.25946778e-03,\n",
       "        9.14831180e-03, -5.99136157e-03,  7.59079382e-02, -5.65579049e-02,\n",
       "        2.51451563e-02,  2.58769020e-02,  1.83682032e-02,  5.11498079e-02,\n",
       "       -1.93466945e-03,  3.20059136e-02, -1.92212183e-02, -6.99391915e-03,\n",
       "       -5.33225611e-02,  1.10472394e-02,  1.96988750e-02, -6.73817657e-03,\n",
       "       -1.68517474e-02, -3.71841784e-03, -2.83320528e-02, -4.04673032e-02,\n",
       "        2.09421646e-02,  2.90706530e-02,  4.67843488e-02, -5.07472940e-02,\n",
       "       -5.35885133e-02,  3.72178927e-02,  2.80560087e-03, -9.97110158e-02,\n",
       "        1.85498185e-02,  4.42457274e-02, -3.80537510e-02, -1.20240021e-02,\n",
       "        4.08029184e-02, -3.88143994e-02, -4.46264893e-02,  5.86090535e-02,\n",
       "       -5.43800779e-02,  2.02510525e-02, -3.24160755e-02, -1.01510221e-02,\n",
       "        3.66747826e-02, -1.53992316e-02, -1.22338552e-02,  2.41609849e-02,\n",
       "        3.13338079e-02,  1.74316356e-03,  2.34306585e-02,  5.89421354e-02,\n",
       "        7.55258463e-03,  3.03856544e-02, -9.33983773e-02, -2.98526846e-02,\n",
       "       -1.12655489e-02, -2.54201479e-02, -7.18333013e-03,  1.24671925e-02,\n",
       "        3.48540395e-02,  1.93721186e-02,  1.51075199e-02, -5.99874090e-03,\n",
       "        4.09119055e-02,  4.01536301e-02,  5.12614772e-02,  4.64251684e-03,\n",
       "       -3.50236967e-02, -5.84874302e-02, -7.68788531e-02, -2.88527168e-04,\n",
       "        5.86460680e-02,  2.99279019e-02, -6.50862232e-02, -7.96695706e-04,\n",
       "        1.90694723e-02, -2.25071912e-03,  3.03035472e-02,  5.02191819e-02,\n",
       "       -4.51343954e-02, -4.32436131e-02,  4.78170589e-02,  2.60772160e-03,\n",
       "       -2.30669603e-02,  3.30332927e-02,  1.77570153e-02, -1.23625323e-02,\n",
       "       -8.32899585e-02,  4.10875119e-02,  7.34367734e-03,  3.87060717e-02,\n",
       "       -7.90474415e-02,  4.34555709e-02,  1.22711016e-02, -1.07096545e-02,\n",
       "        2.55147833e-02,  2.15721782e-02,  3.78124751e-02,  1.23617155e-02,\n",
       "        1.22229038e-02, -6.19402826e-02, -4.86489013e-03, -1.23626739e-02,\n",
       "        5.82297668e-02, -1.11944610e-02, -4.26546596e-02, -2.01684553e-02,\n",
       "       -5.60490182e-03,  3.19506600e-02,  1.03073698e-02, -5.42850583e-04,\n",
       "       -9.72942077e-03,  2.88844779e-02, -3.70495766e-02,  2.79947603e-03,\n",
       "        5.12071513e-02, -2.70963237e-02,  1.04310072e-03,  1.90422591e-02,\n",
       "       -4.69567217e-02,  4.32061888e-02,  4.27740067e-02,  4.12706994e-02,\n",
       "        1.27404621e-02,  3.35471425e-03,  1.06241452e-02,  4.65113018e-03,\n",
       "        3.25117446e-02,  1.99629199e-02, -2.29482763e-02, -3.17125842e-02,\n",
       "        1.06584625e-02,  3.01309843e-02,  2.96941735e-02,  2.91935652e-02,\n",
       "       -9.88230947e-03,  4.09819335e-02,  2.39127222e-02, -1.65761951e-02,\n",
       "        2.36082133e-02,  2.72161849e-02, -2.15065591e-02,  2.72262446e-03,\n",
       "       -9.05826502e-03,  2.46647410e-02,  3.47153991e-02,  1.09562781e-02,\n",
       "       -2.56262887e-02,  8.61581136e-03, -3.56880613e-02,  4.49781679e-02,\n",
       "       -5.16670570e-03, -4.43494171e-02, -3.34211066e-02, -4.01896276e-02,\n",
       "        1.92906312e-03,  2.12966907e-03, -1.42843099e-02, -1.55624803e-02,\n",
       "        3.13620195e-02,  1.05403140e-02,  2.03528702e-02,  4.52127680e-02,\n",
       "        2.34009344e-02, -4.49222960e-02, -4.48264778e-02, -4.00741361e-02,\n",
       "       -3.40180025e-02, -9.69441980e-03, -2.30663680e-02, -1.69077030e-04,\n",
       "       -2.39850804e-02, -3.84747200e-02, -1.25022987e-02, -9.77534615e-03,\n",
       "        2.66351588e-02,  9.56194184e-04, -4.70636375e-02, -2.58634835e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-1.66203845e-02  3.18243094e-02  1.08900415e-02  6.07051626e-02\n -4.78123827e-03  1.11913783e-02 -6.85976222e-02  4.61351424e-02\n -4.64002341e-02 -1.12267621e-02  2.83614602e-02 -4.56234030e-02\n  7.72971362e-02  3.75814810e-02  6.19152375e-02  4.86828275e-02\n  1.76920649e-02 -5.03368815e-03  4.12636138e-02  2.81515792e-02\n  6.77129477e-02 -5.78775108e-02 -1.62556749e-02  1.80227738e-02\n -3.35297063e-02  1.58178154e-02  3.43615450e-02  9.60681122e-03\n -4.21833480e-03  1.61159895e-02  9.31848958e-02 -4.50574942e-02\n -2.59352662e-02  6.35581762e-02 -2.26409975e-02  3.84901017e-02\n -1.16953626e-02  4.39094426e-03 -4.13329415e-02  3.33792083e-02\n -1.83012262e-02 -4.07681465e-02 -5.73155209e-02  6.27704486e-02\n -3.43312472e-02 -3.07545476e-02  2.32101697e-02  9.06041935e-02\n -8.93085729e-03 -7.34184682e-02 -1.31707033e-02 -2.64743157e-02\n -4.25296910e-02 -2.83144843e-02 -6.20349869e-02 -3.36020924e-02\n -7.34354556e-03  2.17808504e-02  3.69347259e-02 -3.86022218e-02\n -7.41071403e-02  1.75898783e-02 -2.62226332e-02 -2.70356294e-02\n -6.87847883e-02  2.06606146e-02 -7.21161738e-02 -1.02998264e-01\n  1.63995847e-03  5.22491476e-03  4.29112017e-02 -1.43741583e-02\n -3.53816934e-02 -1.19941225e-02 -2.57774834e-02 -1.62389930e-02\n  2.50845570e-02 -4.02742578e-03  7.40116090e-02 -3.77577879e-02\n  6.28547892e-02 -1.80537272e-02  1.24830520e-02 -1.22059574e-02\n -2.41444018e-02 -1.96499806e-02 -4.50418107e-02  2.94242501e-02\n -5.76290749e-02  1.57415271e-02  1.70491431e-02 -4.08967882e-02\n  8.91423784e-03  3.91253270e-02 -3.92794348e-02  4.02687080e-02\n -3.96716734e-03  9.40515939e-03 -1.39397522e-03  2.58060009e-03\n -7.77998799e-03  3.04404343e-03 -1.20174615e-02  1.61936767e-02\n  3.05249877e-02 -3.85293830e-03 -5.06774001e-02  1.93908997e-02\n  3.73761123e-03  3.25672515e-03 -2.70200353e-02 -2.13561468e-02\n -3.14152054e-02  3.10632642e-02  4.45960201e-02  1.27361408e-02\n -2.09134482e-02 -1.92486029e-02  1.69681143e-02 -2.60006059e-02\n -5.94309829e-02 -4.86598536e-02 -3.76861617e-02  1.05277998e-02\n  2.54111290e-02  4.03936766e-02 -4.52261083e-02 -5.85269481e-02\n -4.82979640e-02  8.28580409e-02  1.49339251e-02  7.05721155e-02\n  1.95513796e-02 -4.34699282e-02 -1.62216052e-02  5.74295688e-03\n  1.31907612e-02  5.66552654e-02 -5.90578727e-02  3.42485942e-02\n  2.10362934e-02  1.27514517e-02  3.54573950e-02 -2.13489141e-02\n -3.06899007e-02  3.00199050e-03 -2.77244649e-03 -2.12456901e-02\n  4.50271070e-02  1.29388878e-02  2.98859049e-02  6.48989249e-03\n  3.36318798e-02  8.28876346e-02  1.41210982e-03 -1.88193023e-02\n  8.69452301e-03 -3.18056419e-02 -3.46236117e-02  6.10793289e-03\n -3.80899943e-02 -1.20976819e-02  6.03801832e-02  1.03475666e-02\n -8.72565433e-03 -1.65278371e-03 -1.70108769e-02 -9.41414293e-03\n -2.58412398e-02 -3.14017758e-02 -2.38352511e-02 -1.46708516e-02\n  3.01814191e-02  7.90464319e-03 -3.50978295e-03 -1.24804545e-02\n  6.15306869e-02 -4.42779809e-02 -4.44076285e-02 -3.58047485e-02\n -3.06036901e-02  4.96615330e-03  4.43466567e-03 -9.29982495e-03\n  5.19480137e-03  2.87742931e-02 -8.31504352e-03  3.56447995e-02\n -4.01350446e-02 -7.18604848e-02  6.29476388e-04  2.48303358e-02\n -6.70894515e-03  1.43898651e-02  5.85649442e-03  2.75191292e-02\n  1.77840274e-02 -5.48537560e-02 -3.28402258e-02 -8.36072396e-03\n -1.42088523e-02  2.30933838e-02 -2.60523669e-02  5.53226024e-02\n  1.67115789e-03  4.78059500e-02  1.36417756e-02  2.90923752e-02\n -2.16365904e-02 -4.85142954e-02  2.35756300e-02 -3.58560570e-02\n -2.53807916e-03 -1.13497507e-02  5.11154011e-02 -3.32557112e-02\n  4.23142873e-02  1.45196645e-02 -1.18147889e-02  2.42862515e-02\n -1.79522298e-02  3.96828540e-02 -3.30230570e-04 -6.31393865e-03\n -3.00317630e-02 -5.37221693e-02 -5.79714328e-02 -4.98339310e-02\n -2.27033943e-02  2.62795016e-02  9.55829248e-02  9.28109586e-02\n  5.75428195e-02  6.61613536e-04 -3.66864651e-02 -2.56188456e-02\n -5.21785878e-02 -4.53035943e-02 -4.30923849e-02 -4.82301302e-02\n  7.56835192e-03  4.05373499e-02  5.83241414e-03  5.35822958e-02\n  2.92999148e-02 -3.61988433e-02  3.45451273e-02  1.82013884e-02\n -1.56197464e-02  3.16763222e-02 -7.89825991e-02  2.41650064e-02\n -1.44295185e-03 -2.65402347e-02  4.26940583e-02  2.87292693e-02\n  3.65022458e-02  2.28840616e-02 -4.19029184e-02 -3.53155881e-02\n -2.53733918e-02  5.19529842e-02 -4.97282203e-03  5.41276261e-02\n  2.75034066e-02 -5.60938865e-02 -3.08943051e-03 -3.68296425e-03\n -1.01039382e-02 -2.53064539e-02  6.65950403e-02 -1.02273040e-02\n -1.56550836e-02 -4.63015027e-02 -1.60684735e-02  2.90279929e-02\n  1.84524562e-02  4.21807878e-02  2.70528123e-02 -3.92822847e-02\n  1.65486170e-04  3.74678597e-02  2.06510760e-02 -1.91581156e-02\n -2.41806619e-02 -4.93697375e-02  2.37128381e-02  2.93630324e-02\n -1.11068822e-02 -6.53605461e-02 -9.03953519e-03 -1.69197135e-02\n -1.67890266e-03  1.73130147e-02  2.96984315e-02  7.03794940e-04\n  3.49728093e-02  3.76418866e-02 -8.92114080e-03 -7.92817473e-02\n  5.94919920e-02 -2.06741802e-02 -2.82160672e-05  8.48593116e-02\n  6.72488287e-03  5.98037336e-03  5.19943563e-03  9.52106959e-04\n  7.06313923e-03  3.03297061e-02 -2.41889413e-02  5.20864762e-02\n -3.60825211e-02 -1.00199036e-01 -2.09101941e-02 -2.53273174e-02\n -6.91100303e-03 -7.27035105e-02 -2.09585652e-02  4.79063345e-03\n  6.33115172e-02  3.54349539e-02  4.08246256e-02 -2.19057575e-02\n  1.38069913e-02 -2.07701866e-02  5.05773202e-02 -8.56384113e-02\n -1.68402139e-02 -1.55125502e-02  8.15049373e-03 -3.53767760e-02\n -5.52165613e-04 -4.26331051e-02 -2.84059029e-02 -1.66802946e-02\n  1.40272602e-02 -7.83739537e-02  4.44863737e-02 -1.27452919e-02\n -3.02322465e-03 -1.59100275e-02 -6.65013865e-02  3.43179442e-02\n  4.98073176e-02 -4.93976697e-02  1.40055427e-02 -6.34419248e-02\n -9.82448086e-03  5.05948067e-03 -4.34769019e-02  4.04147469e-02\n  1.90878958e-02 -1.61001422e-02  6.15959987e-03  3.58245857e-02\n -4.19794861e-03  6.51705265e-02 -1.23145944e-02 -1.70439295e-02\n  2.77958475e-02 -5.45461327e-02 -2.21467316e-02 -2.79195514e-02\n -2.90510505e-02  3.39402147e-02  2.68027303e-03  1.19058334e-03\n  2.16071587e-02 -1.37163093e-02  2.36012898e-02  2.24262159e-02\n  5.75308688e-02  5.00003286e-02  4.61008884e-02  5.59287891e-03\n  5.44104550e-04  4.36788537e-02 -2.22671239e-04  6.68572187e-02\n -4.56012087e-03 -4.40934040e-02 -5.98515086e-02  2.14390550e-02\n  5.56597076e-02 -3.06031313e-02 -3.54552083e-02 -3.55060422e-03\n -5.62020950e-02 -7.93476030e-02  4.48586494e-02 -2.71551851e-02\n -2.31015645e-02  8.15386605e-03 -4.98608314e-02 -3.08012683e-02\n  6.92976266e-02 -5.70026552e-03 -6.37547374e-02  3.61091271e-02\n -5.78369536e-02  1.92431509e-02 -4.36948650e-02  2.21934281e-02\n -6.08947836e-02  1.74561292e-02  1.65475234e-02  2.81844642e-02\n  5.01934811e-03 -1.92064904e-02 -1.03496807e-02 -2.47444622e-02\n -1.98516957e-02 -2.22331434e-02  5.84748434e-03  6.05603727e-03\n -7.41347950e-03 -3.37890871e-02 -1.12721976e-02  4.64321896e-02\n  3.63264270e-02 -6.58817869e-03  5.39251715e-02  3.86603214e-02\n  2.81504896e-02 -5.39201603e-04 -5.43320067e-02 -9.98929376e-04\n  7.02198148e-02 -2.70939320e-02  4.97998521e-02 -3.26503851e-02\n -2.72068456e-02 -1.18638435e-02  3.54213044e-02 -1.70626715e-02\n  2.57567205e-02 -1.63065605e-02  8.00992697e-02  3.13078910e-02\n -2.12719887e-02 -4.01813090e-02 -9.39684920e-03  4.80123647e-02\n  6.22941293e-02  3.79541777e-02 -5.87280327e-03 -1.39003843e-02\n  2.77720205e-02  2.44838255e-03 -9.46688503e-02  1.15031349e-02\n -3.69596407e-02  3.40982191e-02  6.65755104e-03  1.29722618e-03\n -1.38026550e-02  7.15275779e-02  2.91499356e-03 -3.26661915e-02\n -4.22307737e-02  1.19368071e-02 -4.70004305e-02 -3.42741120e-03\n  2.75241192e-02  1.32566793e-02  8.93166214e-02 -5.12588471e-02\n  1.31264161e-02  3.80690419e-03 -3.82817201e-02  1.18098557e-02\n -3.24115679e-02  5.30428514e-02 -7.38666579e-02  3.70953744e-03\n  9.19492636e-03  1.15195177e-02  4.10647541e-02 -2.63514556e-03\n  1.21841850e-02  4.41187136e-02 -1.34935332e-02 -1.18063660e-02\n -3.14735547e-02  5.06005436e-02  3.41203958e-02  2.77609173e-02\n  9.19957832e-03 -5.86389937e-02 -5.77792786e-02 -4.13225032e-02\n -9.09921080e-02  7.51200411e-03 -5.17122969e-02 -8.55998397e-02\n  2.58105807e-02 -1.64746139e-02  4.00950480e-03  9.54273739e-04\n -3.80919278e-02 -4.48095649e-02 -6.63738605e-03  2.64671408e-02\n -3.63813974e-02 -4.88996468e-02  2.64815092e-02 -5.04127592e-02\n -2.98593584e-02  3.92318629e-02 -1.48621211e-02  2.55758073e-02\n  3.12475283e-02  1.37613993e-02  1.93044152e-02 -5.85279167e-02\n -2.72733457e-02 -1.52201578e-03 -4.05081920e-03 -6.04223609e-02\n -2.53634411e-03 -4.21233550e-02 -3.09319552e-02  1.19652059e-02\n -9.70497914e-03 -1.64421201e-02 -5.52505180e-02  1.42119415e-02\n -4.08344029e-04 -5.91766601e-03 -3.66795994e-02  6.45947643e-03\n  8.20040144e-03 -1.07018007e-02  6.67068223e-03  5.69930933e-02\n  3.53912488e-02 -4.15058061e-02  2.35409606e-02  3.38900834e-02\n -3.64155583e-02  4.97023836e-02  4.32611629e-02 -5.37529215e-02\n -3.79894562e-02 -4.56845276e-02 -7.90513679e-02  7.69593613e-03\n  5.08294739e-02  1.30306780e-02 -2.18444839e-02  1.39003377e-02\n -4.38336609e-03  3.46718840e-02  1.29607022e-02 -4.53655422e-02\n -8.37577973e-03  3.69452909e-02 -3.73046249e-02 -1.73582286e-02\n  6.97481958e-03 -3.96154933e-02 -3.84273157e-02  1.99466813e-02\n -4.47764657e-02 -5.10696322e-02  3.52854803e-02  6.72927126e-02\n  2.70650107e-02  1.20056858e-02 -2.62546893e-02 -8.26773643e-02\n -2.79018972e-02 -6.56610131e-02 -2.14425046e-02  9.33709834e-03\n  3.85401398e-02 -3.81038501e-03 -4.87416647e-02  5.87947760e-03\n -2.68673711e-03 -6.30394882e-03 -4.28591967e-02 -4.46124142e-03\n  3.07160951e-02  9.26933775e-04 -9.85659752e-03  2.80361883e-02\n -6.14868030e-02  3.78471315e-02 -2.09055352e-03  8.25946778e-03\n  9.14831180e-03 -5.99136157e-03  7.59079382e-02 -5.65579049e-02\n  2.51451563e-02  2.58769020e-02  1.83682032e-02  5.11498079e-02\n -1.93466945e-03  3.20059136e-02 -1.92212183e-02 -6.99391915e-03\n -5.33225611e-02  1.10472394e-02  1.96988750e-02 -6.73817657e-03\n -1.68517474e-02 -3.71841784e-03 -2.83320528e-02 -4.04673032e-02\n  2.09421646e-02  2.90706530e-02  4.67843488e-02 -5.07472940e-02\n -5.35885133e-02  3.72178927e-02  2.80560087e-03 -9.97110158e-02\n  1.85498185e-02  4.42457274e-02 -3.80537510e-02 -1.20240021e-02\n  4.08029184e-02 -3.88143994e-02 -4.46264893e-02  5.86090535e-02\n -5.43800779e-02  2.02510525e-02 -3.24160755e-02 -1.01510221e-02\n  3.66747826e-02 -1.53992316e-02 -1.22338552e-02  2.41609849e-02\n  3.13338079e-02  1.74316356e-03  2.34306585e-02  5.89421354e-02\n  7.55258463e-03  3.03856544e-02 -9.33983773e-02 -2.98526846e-02\n -1.12655489e-02 -2.54201479e-02 -7.18333013e-03  1.24671925e-02\n  3.48540395e-02  1.93721186e-02  1.51075199e-02 -5.99874090e-03\n  4.09119055e-02  4.01536301e-02  5.12614772e-02  4.64251684e-03\n -3.50236967e-02 -5.84874302e-02 -7.68788531e-02 -2.88527168e-04\n  5.86460680e-02  2.99279019e-02 -6.50862232e-02 -7.96695706e-04\n  1.90694723e-02 -2.25071912e-03  3.03035472e-02  5.02191819e-02\n -4.51343954e-02 -4.32436131e-02  4.78170589e-02  2.60772160e-03\n -2.30669603e-02  3.30332927e-02  1.77570153e-02 -1.23625323e-02\n -8.32899585e-02  4.10875119e-02  7.34367734e-03  3.87060717e-02\n -7.90474415e-02  4.34555709e-02  1.22711016e-02 -1.07096545e-02\n  2.55147833e-02  2.15721782e-02  3.78124751e-02  1.23617155e-02\n  1.22229038e-02 -6.19402826e-02 -4.86489013e-03 -1.23626739e-02\n  5.82297668e-02 -1.11944610e-02 -4.26546596e-02 -2.01684553e-02\n -5.60490182e-03  3.19506600e-02  1.03073698e-02 -5.42850583e-04\n -9.72942077e-03  2.88844779e-02 -3.70495766e-02  2.79947603e-03\n  5.12071513e-02 -2.70963237e-02  1.04310072e-03  1.90422591e-02\n -4.69567217e-02  4.32061888e-02  4.27740067e-02  4.12706994e-02\n  1.27404621e-02  3.35471425e-03  1.06241452e-02  4.65113018e-03\n  3.25117446e-02  1.99629199e-02 -2.29482763e-02 -3.17125842e-02\n  1.06584625e-02  3.01309843e-02  2.96941735e-02  2.91935652e-02\n -9.88230947e-03  4.09819335e-02  2.39127222e-02 -1.65761951e-02\n  2.36082133e-02  2.72161849e-02 -2.15065591e-02  2.72262446e-03\n -9.05826502e-03  2.46647410e-02  3.47153991e-02  1.09562781e-02\n -2.56262887e-02  8.61581136e-03 -3.56880613e-02  4.49781679e-02\n -5.16670570e-03 -4.43494171e-02 -3.34211066e-02 -4.01896276e-02\n  1.92906312e-03  2.12966907e-03 -1.42843099e-02 -1.55624803e-02\n  3.13620195e-02  1.05403140e-02  2.03528702e-02  4.52127680e-02\n  2.34009344e-02 -4.49222960e-02 -4.48264778e-02 -4.00741361e-02\n -3.40180025e-02 -9.69441980e-03 -2.30663680e-02 -1.69077030e-04\n -2.39850804e-02 -3.84747200e-02 -1.25022987e-02 -9.77534615e-03\n  2.66351588e-02  9.56194184e-04 -4.70636375e-02 -2.58634835e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarity scores\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Apply Sharpened Cosine Similarity with exponent of 3\u001b[39;00m\n\u001b[1;32m      5\u001b[0m sharpened_scores \u001b[38;5;241m=\u001b[39m scores \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_promt_reversal/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_promt_reversal/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1657\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1614\u001b[0m \n\u001b[1;32m   1615\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1657\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1659\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_promt_reversal/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:164\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    155\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    156\u001b[0m         X,\n\u001b[1;32m    157\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    173\u001b[0m         Y,\n\u001b[1;32m    174\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_promt_reversal/lib/python3.11/site-packages/sklearn/utils/validation.py:1035\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1029\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1030\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1032\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1033\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1034\u001b[0m             )\n\u001b[0;32m-> 1035\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1041\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-1.66203845e-02  3.18243094e-02  1.08900415e-02  6.07051626e-02\n -4.78123827e-03  1.11913783e-02 -6.85976222e-02  4.61351424e-02\n -4.64002341e-02 -1.12267621e-02  2.83614602e-02 -4.56234030e-02\n  7.72971362e-02  3.75814810e-02  6.19152375e-02  4.86828275e-02\n  1.76920649e-02 -5.03368815e-03  4.12636138e-02  2.81515792e-02\n  6.77129477e-02 -5.78775108e-02 -1.62556749e-02  1.80227738e-02\n -3.35297063e-02  1.58178154e-02  3.43615450e-02  9.60681122e-03\n -4.21833480e-03  1.61159895e-02  9.31848958e-02 -4.50574942e-02\n -2.59352662e-02  6.35581762e-02 -2.26409975e-02  3.84901017e-02\n -1.16953626e-02  4.39094426e-03 -4.13329415e-02  3.33792083e-02\n -1.83012262e-02 -4.07681465e-02 -5.73155209e-02  6.27704486e-02\n -3.43312472e-02 -3.07545476e-02  2.32101697e-02  9.06041935e-02\n -8.93085729e-03 -7.34184682e-02 -1.31707033e-02 -2.64743157e-02\n -4.25296910e-02 -2.83144843e-02 -6.20349869e-02 -3.36020924e-02\n -7.34354556e-03  2.17808504e-02  3.69347259e-02 -3.86022218e-02\n -7.41071403e-02  1.75898783e-02 -2.62226332e-02 -2.70356294e-02\n -6.87847883e-02  2.06606146e-02 -7.21161738e-02 -1.02998264e-01\n  1.63995847e-03  5.22491476e-03  4.29112017e-02 -1.43741583e-02\n -3.53816934e-02 -1.19941225e-02 -2.57774834e-02 -1.62389930e-02\n  2.50845570e-02 -4.02742578e-03  7.40116090e-02 -3.77577879e-02\n  6.28547892e-02 -1.80537272e-02  1.24830520e-02 -1.22059574e-02\n -2.41444018e-02 -1.96499806e-02 -4.50418107e-02  2.94242501e-02\n -5.76290749e-02  1.57415271e-02  1.70491431e-02 -4.08967882e-02\n  8.91423784e-03  3.91253270e-02 -3.92794348e-02  4.02687080e-02\n -3.96716734e-03  9.40515939e-03 -1.39397522e-03  2.58060009e-03\n -7.77998799e-03  3.04404343e-03 -1.20174615e-02  1.61936767e-02\n  3.05249877e-02 -3.85293830e-03 -5.06774001e-02  1.93908997e-02\n  3.73761123e-03  3.25672515e-03 -2.70200353e-02 -2.13561468e-02\n -3.14152054e-02  3.10632642e-02  4.45960201e-02  1.27361408e-02\n -2.09134482e-02 -1.92486029e-02  1.69681143e-02 -2.60006059e-02\n -5.94309829e-02 -4.86598536e-02 -3.76861617e-02  1.05277998e-02\n  2.54111290e-02  4.03936766e-02 -4.52261083e-02 -5.85269481e-02\n -4.82979640e-02  8.28580409e-02  1.49339251e-02  7.05721155e-02\n  1.95513796e-02 -4.34699282e-02 -1.62216052e-02  5.74295688e-03\n  1.31907612e-02  5.66552654e-02 -5.90578727e-02  3.42485942e-02\n  2.10362934e-02  1.27514517e-02  3.54573950e-02 -2.13489141e-02\n -3.06899007e-02  3.00199050e-03 -2.77244649e-03 -2.12456901e-02\n  4.50271070e-02  1.29388878e-02  2.98859049e-02  6.48989249e-03\n  3.36318798e-02  8.28876346e-02  1.41210982e-03 -1.88193023e-02\n  8.69452301e-03 -3.18056419e-02 -3.46236117e-02  6.10793289e-03\n -3.80899943e-02 -1.20976819e-02  6.03801832e-02  1.03475666e-02\n -8.72565433e-03 -1.65278371e-03 -1.70108769e-02 -9.41414293e-03\n -2.58412398e-02 -3.14017758e-02 -2.38352511e-02 -1.46708516e-02\n  3.01814191e-02  7.90464319e-03 -3.50978295e-03 -1.24804545e-02\n  6.15306869e-02 -4.42779809e-02 -4.44076285e-02 -3.58047485e-02\n -3.06036901e-02  4.96615330e-03  4.43466567e-03 -9.29982495e-03\n  5.19480137e-03  2.87742931e-02 -8.31504352e-03  3.56447995e-02\n -4.01350446e-02 -7.18604848e-02  6.29476388e-04  2.48303358e-02\n -6.70894515e-03  1.43898651e-02  5.85649442e-03  2.75191292e-02\n  1.77840274e-02 -5.48537560e-02 -3.28402258e-02 -8.36072396e-03\n -1.42088523e-02  2.30933838e-02 -2.60523669e-02  5.53226024e-02\n  1.67115789e-03  4.78059500e-02  1.36417756e-02  2.90923752e-02\n -2.16365904e-02 -4.85142954e-02  2.35756300e-02 -3.58560570e-02\n -2.53807916e-03 -1.13497507e-02  5.11154011e-02 -3.32557112e-02\n  4.23142873e-02  1.45196645e-02 -1.18147889e-02  2.42862515e-02\n -1.79522298e-02  3.96828540e-02 -3.30230570e-04 -6.31393865e-03\n -3.00317630e-02 -5.37221693e-02 -5.79714328e-02 -4.98339310e-02\n -2.27033943e-02  2.62795016e-02  9.55829248e-02  9.28109586e-02\n  5.75428195e-02  6.61613536e-04 -3.66864651e-02 -2.56188456e-02\n -5.21785878e-02 -4.53035943e-02 -4.30923849e-02 -4.82301302e-02\n  7.56835192e-03  4.05373499e-02  5.83241414e-03  5.35822958e-02\n  2.92999148e-02 -3.61988433e-02  3.45451273e-02  1.82013884e-02\n -1.56197464e-02  3.16763222e-02 -7.89825991e-02  2.41650064e-02\n -1.44295185e-03 -2.65402347e-02  4.26940583e-02  2.87292693e-02\n  3.65022458e-02  2.28840616e-02 -4.19029184e-02 -3.53155881e-02\n -2.53733918e-02  5.19529842e-02 -4.97282203e-03  5.41276261e-02\n  2.75034066e-02 -5.60938865e-02 -3.08943051e-03 -3.68296425e-03\n -1.01039382e-02 -2.53064539e-02  6.65950403e-02 -1.02273040e-02\n -1.56550836e-02 -4.63015027e-02 -1.60684735e-02  2.90279929e-02\n  1.84524562e-02  4.21807878e-02  2.70528123e-02 -3.92822847e-02\n  1.65486170e-04  3.74678597e-02  2.06510760e-02 -1.91581156e-02\n -2.41806619e-02 -4.93697375e-02  2.37128381e-02  2.93630324e-02\n -1.11068822e-02 -6.53605461e-02 -9.03953519e-03 -1.69197135e-02\n -1.67890266e-03  1.73130147e-02  2.96984315e-02  7.03794940e-04\n  3.49728093e-02  3.76418866e-02 -8.92114080e-03 -7.92817473e-02\n  5.94919920e-02 -2.06741802e-02 -2.82160672e-05  8.48593116e-02\n  6.72488287e-03  5.98037336e-03  5.19943563e-03  9.52106959e-04\n  7.06313923e-03  3.03297061e-02 -2.41889413e-02  5.20864762e-02\n -3.60825211e-02 -1.00199036e-01 -2.09101941e-02 -2.53273174e-02\n -6.91100303e-03 -7.27035105e-02 -2.09585652e-02  4.79063345e-03\n  6.33115172e-02  3.54349539e-02  4.08246256e-02 -2.19057575e-02\n  1.38069913e-02 -2.07701866e-02  5.05773202e-02 -8.56384113e-02\n -1.68402139e-02 -1.55125502e-02  8.15049373e-03 -3.53767760e-02\n -5.52165613e-04 -4.26331051e-02 -2.84059029e-02 -1.66802946e-02\n  1.40272602e-02 -7.83739537e-02  4.44863737e-02 -1.27452919e-02\n -3.02322465e-03 -1.59100275e-02 -6.65013865e-02  3.43179442e-02\n  4.98073176e-02 -4.93976697e-02  1.40055427e-02 -6.34419248e-02\n -9.82448086e-03  5.05948067e-03 -4.34769019e-02  4.04147469e-02\n  1.90878958e-02 -1.61001422e-02  6.15959987e-03  3.58245857e-02\n -4.19794861e-03  6.51705265e-02 -1.23145944e-02 -1.70439295e-02\n  2.77958475e-02 -5.45461327e-02 -2.21467316e-02 -2.79195514e-02\n -2.90510505e-02  3.39402147e-02  2.68027303e-03  1.19058334e-03\n  2.16071587e-02 -1.37163093e-02  2.36012898e-02  2.24262159e-02\n  5.75308688e-02  5.00003286e-02  4.61008884e-02  5.59287891e-03\n  5.44104550e-04  4.36788537e-02 -2.22671239e-04  6.68572187e-02\n -4.56012087e-03 -4.40934040e-02 -5.98515086e-02  2.14390550e-02\n  5.56597076e-02 -3.06031313e-02 -3.54552083e-02 -3.55060422e-03\n -5.62020950e-02 -7.93476030e-02  4.48586494e-02 -2.71551851e-02\n -2.31015645e-02  8.15386605e-03 -4.98608314e-02 -3.08012683e-02\n  6.92976266e-02 -5.70026552e-03 -6.37547374e-02  3.61091271e-02\n -5.78369536e-02  1.92431509e-02 -4.36948650e-02  2.21934281e-02\n -6.08947836e-02  1.74561292e-02  1.65475234e-02  2.81844642e-02\n  5.01934811e-03 -1.92064904e-02 -1.03496807e-02 -2.47444622e-02\n -1.98516957e-02 -2.22331434e-02  5.84748434e-03  6.05603727e-03\n -7.41347950e-03 -3.37890871e-02 -1.12721976e-02  4.64321896e-02\n  3.63264270e-02 -6.58817869e-03  5.39251715e-02  3.86603214e-02\n  2.81504896e-02 -5.39201603e-04 -5.43320067e-02 -9.98929376e-04\n  7.02198148e-02 -2.70939320e-02  4.97998521e-02 -3.26503851e-02\n -2.72068456e-02 -1.18638435e-02  3.54213044e-02 -1.70626715e-02\n  2.57567205e-02 -1.63065605e-02  8.00992697e-02  3.13078910e-02\n -2.12719887e-02 -4.01813090e-02 -9.39684920e-03  4.80123647e-02\n  6.22941293e-02  3.79541777e-02 -5.87280327e-03 -1.39003843e-02\n  2.77720205e-02  2.44838255e-03 -9.46688503e-02  1.15031349e-02\n -3.69596407e-02  3.40982191e-02  6.65755104e-03  1.29722618e-03\n -1.38026550e-02  7.15275779e-02  2.91499356e-03 -3.26661915e-02\n -4.22307737e-02  1.19368071e-02 -4.70004305e-02 -3.42741120e-03\n  2.75241192e-02  1.32566793e-02  8.93166214e-02 -5.12588471e-02\n  1.31264161e-02  3.80690419e-03 -3.82817201e-02  1.18098557e-02\n -3.24115679e-02  5.30428514e-02 -7.38666579e-02  3.70953744e-03\n  9.19492636e-03  1.15195177e-02  4.10647541e-02 -2.63514556e-03\n  1.21841850e-02  4.41187136e-02 -1.34935332e-02 -1.18063660e-02\n -3.14735547e-02  5.06005436e-02  3.41203958e-02  2.77609173e-02\n  9.19957832e-03 -5.86389937e-02 -5.77792786e-02 -4.13225032e-02\n -9.09921080e-02  7.51200411e-03 -5.17122969e-02 -8.55998397e-02\n  2.58105807e-02 -1.64746139e-02  4.00950480e-03  9.54273739e-04\n -3.80919278e-02 -4.48095649e-02 -6.63738605e-03  2.64671408e-02\n -3.63813974e-02 -4.88996468e-02  2.64815092e-02 -5.04127592e-02\n -2.98593584e-02  3.92318629e-02 -1.48621211e-02  2.55758073e-02\n  3.12475283e-02  1.37613993e-02  1.93044152e-02 -5.85279167e-02\n -2.72733457e-02 -1.52201578e-03 -4.05081920e-03 -6.04223609e-02\n -2.53634411e-03 -4.21233550e-02 -3.09319552e-02  1.19652059e-02\n -9.70497914e-03 -1.64421201e-02 -5.52505180e-02  1.42119415e-02\n -4.08344029e-04 -5.91766601e-03 -3.66795994e-02  6.45947643e-03\n  8.20040144e-03 -1.07018007e-02  6.67068223e-03  5.69930933e-02\n  3.53912488e-02 -4.15058061e-02  2.35409606e-02  3.38900834e-02\n -3.64155583e-02  4.97023836e-02  4.32611629e-02 -5.37529215e-02\n -3.79894562e-02 -4.56845276e-02 -7.90513679e-02  7.69593613e-03\n  5.08294739e-02  1.30306780e-02 -2.18444839e-02  1.39003377e-02\n -4.38336609e-03  3.46718840e-02  1.29607022e-02 -4.53655422e-02\n -8.37577973e-03  3.69452909e-02 -3.73046249e-02 -1.73582286e-02\n  6.97481958e-03 -3.96154933e-02 -3.84273157e-02  1.99466813e-02\n -4.47764657e-02 -5.10696322e-02  3.52854803e-02  6.72927126e-02\n  2.70650107e-02  1.20056858e-02 -2.62546893e-02 -8.26773643e-02\n -2.79018972e-02 -6.56610131e-02 -2.14425046e-02  9.33709834e-03\n  3.85401398e-02 -3.81038501e-03 -4.87416647e-02  5.87947760e-03\n -2.68673711e-03 -6.30394882e-03 -4.28591967e-02 -4.46124142e-03\n  3.07160951e-02  9.26933775e-04 -9.85659752e-03  2.80361883e-02\n -6.14868030e-02  3.78471315e-02 -2.09055352e-03  8.25946778e-03\n  9.14831180e-03 -5.99136157e-03  7.59079382e-02 -5.65579049e-02\n  2.51451563e-02  2.58769020e-02  1.83682032e-02  5.11498079e-02\n -1.93466945e-03  3.20059136e-02 -1.92212183e-02 -6.99391915e-03\n -5.33225611e-02  1.10472394e-02  1.96988750e-02 -6.73817657e-03\n -1.68517474e-02 -3.71841784e-03 -2.83320528e-02 -4.04673032e-02\n  2.09421646e-02  2.90706530e-02  4.67843488e-02 -5.07472940e-02\n -5.35885133e-02  3.72178927e-02  2.80560087e-03 -9.97110158e-02\n  1.85498185e-02  4.42457274e-02 -3.80537510e-02 -1.20240021e-02\n  4.08029184e-02 -3.88143994e-02 -4.46264893e-02  5.86090535e-02\n -5.43800779e-02  2.02510525e-02 -3.24160755e-02 -1.01510221e-02\n  3.66747826e-02 -1.53992316e-02 -1.22338552e-02  2.41609849e-02\n  3.13338079e-02  1.74316356e-03  2.34306585e-02  5.89421354e-02\n  7.55258463e-03  3.03856544e-02 -9.33983773e-02 -2.98526846e-02\n -1.12655489e-02 -2.54201479e-02 -7.18333013e-03  1.24671925e-02\n  3.48540395e-02  1.93721186e-02  1.51075199e-02 -5.99874090e-03\n  4.09119055e-02  4.01536301e-02  5.12614772e-02  4.64251684e-03\n -3.50236967e-02 -5.84874302e-02 -7.68788531e-02 -2.88527168e-04\n  5.86460680e-02  2.99279019e-02 -6.50862232e-02 -7.96695706e-04\n  1.90694723e-02 -2.25071912e-03  3.03035472e-02  5.02191819e-02\n -4.51343954e-02 -4.32436131e-02  4.78170589e-02  2.60772160e-03\n -2.30669603e-02  3.30332927e-02  1.77570153e-02 -1.23625323e-02\n -8.32899585e-02  4.10875119e-02  7.34367734e-03  3.87060717e-02\n -7.90474415e-02  4.34555709e-02  1.22711016e-02 -1.07096545e-02\n  2.55147833e-02  2.15721782e-02  3.78124751e-02  1.23617155e-02\n  1.22229038e-02 -6.19402826e-02 -4.86489013e-03 -1.23626739e-02\n  5.82297668e-02 -1.11944610e-02 -4.26546596e-02 -2.01684553e-02\n -5.60490182e-03  3.19506600e-02  1.03073698e-02 -5.42850583e-04\n -9.72942077e-03  2.88844779e-02 -3.70495766e-02  2.79947603e-03\n  5.12071513e-02 -2.70963237e-02  1.04310072e-03  1.90422591e-02\n -4.69567217e-02  4.32061888e-02  4.27740067e-02  4.12706994e-02\n  1.27404621e-02  3.35471425e-03  1.06241452e-02  4.65113018e-03\n  3.25117446e-02  1.99629199e-02 -2.29482763e-02 -3.17125842e-02\n  1.06584625e-02  3.01309843e-02  2.96941735e-02  2.91935652e-02\n -9.88230947e-03  4.09819335e-02  2.39127222e-02 -1.65761951e-02\n  2.36082133e-02  2.72161849e-02 -2.15065591e-02  2.72262446e-03\n -9.05826502e-03  2.46647410e-02  3.47153991e-02  1.09562781e-02\n -2.56262887e-02  8.61581136e-03 -3.56880613e-02  4.49781679e-02\n -5.16670570e-03 -4.43494171e-02 -3.34211066e-02 -4.01896276e-02\n  1.92906312e-03  2.12966907e-03 -1.42843099e-02 -1.55624803e-02\n  3.13620195e-02  1.05403140e-02  2.03528702e-02  4.52127680e-02\n  2.34009344e-02 -4.49222960e-02 -4.48264778e-02 -4.00741361e-02\n -3.40180025e-02 -9.69441980e-03 -2.30663680e-02 -1.69077030e-04\n -2.39850804e-02 -3.84747200e-02 -1.25022987e-02 -9.77534615e-03\n  2.66351588e-02  9.56194184e-04 -4.70636375e-02 -2.58634835e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate cosine similarity scores\n",
    "scores = cosine_similarity(predicted_embeddings, expected_embeddings)\n",
    "\n",
    "# Apply Sharpened Cosine Similarity with exponent of 3\n",
    "sharpened_scores = scores ** 3\n",
    "sharpened_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_promt_reversal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
