{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datasets import load_dataset\n",
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = None\n",
    "final_df = None\n",
    "\n",
    "def add_to_df(df, out_df = None):\n",
    "    if out_df is None:\n",
    "        out_df = df\n",
    "    else:\n",
    "        out_df = out_df.extend(df)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './supplementary-texts-rewritten-by-genai-models/test.csv'\n",
    "\n",
    "df = pl.read_csv(data_path).select('original_text').unique().with_columns([\n",
    "    pl.lit('supplementary-texts-rewritten-by-genai-models').alias('source')\n",
    "])\n",
    "\n",
    "temp_df = add_to_df(df, temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/euclaise/writingprompts\n",
    "ds = load_dataset('euclaise/writingprompts')\n",
    "df = pl.from_arrow(ds['train'].data.table).select(\n",
    "    pl.col('story').alias('original_text'),\n",
    "    pl.lit('writingprompts').alias('source')\n",
    ")\n",
    "temp_df = add_to_df(df, temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/Abirate/english_quotes\n",
    "ds = load_dataset('Abirate/english_quotes')\n",
    "df = pl.from_arrow(ds['train'].data.table).select(\n",
    "    pl.col('quote').alias('original_text'),\n",
    "    pl.lit('english_quotes').alias('source')\n",
    ")\n",
    "temp_df = add_to_df(df, temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./nyt-comments\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/aashita/nyt-comments\n",
    "\n",
    "dataset_url = 'https://www.kaggle.com/datasets/aashita/nyt-comments'\n",
    "ods = od.download(dataset_url)\n",
    "\n",
    "ds_path = '/home/lawrence/Projects/contests/llm_prompt_recovery/nyt-comments/CommentsApril2018.csv'\n",
    "\n",
    "df = pl.read_csv(ds_path).select(\n",
    "    pl.col('commentBody').alias('original_text'),\n",
    "    pl.lit('nyt-comments').alias('source')\n",
    ")\n",
    "\n",
    "temp_df = add_to_df(df, temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.with_columns([\n",
    "    pl.col('original_text').str.len_chars().alias('og_text_len'),\n",
    "    pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"og_text_id\")\n",
    "]).filter(\n",
    "    pl.col('og_text_len') < 500\n",
    ").unique('original_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in temp_df['source'].unique().to_list():\n",
    "    if source == 'supplementary-texts-rewritten-by-genai-models':\n",
    "        final_df = add_to_df(temp_df.filter(pl.col('source') == source).sample(fraction=1), final_df)\n",
    "    elif source == 'writingprompts':\n",
    "        final_df = add_to_df(temp_df.filter(pl.col('source') == source).sample(fraction=1), final_df)\n",
    "    elif source == 'english_quotes':\n",
    "        final_df = add_to_df(temp_df.filter(pl.col('source') == source).sample(n=1200), final_df)\n",
    "    elif source == 'nyt-comments':\n",
    "        final_df = add_to_df(temp_df.filter(pl.col('source') == source).sample(n=1200), final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.unique('original_text').write_csv('data/original_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import spacy_fastlang\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"language_detector\")\n",
    "\n",
    "def get_lang(text: str) -> str:\n",
    "    doc = nlp(text)\n",
    "    return doc._.language\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.with_columns([\n",
    "    pl.col(\"original_text\").map_elements(get_lang).alias(\"lang\"),\n",
    "]).filter(pl.col('lang') == 'en') #.write_csv('data/original_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.unique('original_text').write_csv('data/original_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_parquet(\"./data/train_data_2/*.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Competency to be Acquired:**\\n\\nThe ability to advocate effectively for oneself and ensure the protection of one's well-being in the face of biased social workers who may prioritize personal biases over the best interests of the child.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[88,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.filter(\n",
    "    # pl.col('generated_text').str.contains('\\*\\*.*\\*\\*'),\n",
    "    ~pl.col('generated_text').str.contains('I am unable')\n",
    ").write_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/train_data_2/cleaned.parquet'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "path: pathlib.Path =  \"./data/train_data_2/cleaned.parquet\"\n",
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_promt_reversal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
